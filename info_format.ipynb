{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cee08e-980e-4a76-b41c-bfffd7f39f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6fc2bc-79d1-4e29-b784-d1f072c59f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output par to a .txt file\n",
    "output_file = '/home/paulc600/local/HYPE Inputs/info.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af49ae4-a78e-4e06-85eb-1e6cbf41319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out first text section\n",
    "s1= [\n",
    "\"\"\"!! ----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! HYPE - Milk River & St. Mary's River HYPE\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!! Check Indata during first runs (deactivate after first runs) \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d99401c-e25a-429b-be6a-994a41bf43ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s1 in output file\n",
    "with open(output_file, 'w') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s1:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205500a5-e91a-4abe-988e-f029335c6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create first dataframe\n",
    "df1_row=['indatacheckonoff','indatachecklevel']\n",
    "df1_val=[2,2]\n",
    "df1=pd.DataFrame(df1_val, index=df1_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7647a9-9627-4801-84c2-936bf1310d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df1\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df1.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a28d7f-1100-47fe-8d15-70d41c1be395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out first text section\n",
    "s2= [\n",
    "\"\"\"!!\n",
    "!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\n",
    "!! Simulation settings:\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db40330b-d3d7-4ec6-8952-2085748fe319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s2 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s2:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7579c977-b0ad-4dfa-8eb8-549d61708f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df2\n",
    "df2_row=['bdate','cdate','edate','resultdir','instate']\n",
    "df2_val=['1980-01-01','1980-01-01','1982-01-02','/home/paulc600/scratch/HYPE_01/', 'n']\n",
    "df2=pd.DataFrame(df2_val, index=df2_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9761a51d-0c85-4331-992e-3961e240a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df2\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df2.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ed759b-314b-48b5-a611-fd7762706264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s3\n",
    "s3= [\n",
    "\"\"\"!! outstatedate \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "150172bd-0247-465b-8e02-dc6eadcca90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s3 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s3:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5e14cb-a7c7-499d-ba49-2b44ff90178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df3\n",
    "df3_row=['readdaily','submodel','calibration','readobsid','soilstretch']\n",
    "df3_val=['y','n','n','n','n']\n",
    "df3=pd.DataFrame(df3_val, index=df3_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50349926-e965-4ccd-bdc3-29a5ff24aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df3\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df3.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c096930-3c12-4da4-b921-cc54998dabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s4\n",
    "s4= [\n",
    "\"\"\"!! Soilstretch enable the use of soilcorr parameters (strech soildepths in layer 2 and 3)\n",
    "steplength\t1d\t\t\t\t\t\t\t\n",
    "!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Enable/disable optional input files\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d9b038a-4585-47f9-8b51-76016e506283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s4 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s4:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a53d9cd7-30f8-424a-ae17-78df5c2496e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df4\n",
    "df4_row=['readsfobs','readswobs','readuobs','readrhobs','readtminobs','readtmaxobs','soiliniwet','usestop84']\n",
    "df4_val=['n','n','n','n','n','n','n','n']\n",
    "df4=pd.DataFrame(df4_val, index=df4_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f55ba3a9-0514-4664-8b0c-d19d3736b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the corresponding comments\n",
    "c1 = [\n",
    "    \"!! For observed snowfall fractions in SFobs.txt\",\n",
    "    \"!! For observed shortwave radiation in SWobs.txt\",\n",
    "    \"!! For observed wind speeds in Uobs.txt\",\n",
    "    \"!! For observed relative humidity in RHobs.txt\",\n",
    "    \"!! For observed min air temperature in TMINobs.txt\",\n",
    "    \"!! For observed max air temperature in TMAXobs.txt\",\n",
    "    \"!! initiates soil water to porosity instead of field capacity which is default (N). Set Y to use porosity.\",\n",
    "    \"!! initiates soil water to porosity instead of field capacity which is default (N). Set Y to use porosity.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d41a92c-9a98-49a1-9b88-c2ff3b78e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append c1 and df4\n",
    "with open(output_file, 'a') as file:\n",
    "    # Iterate over DataFrame rows\n",
    "    for i, (index, row) in enumerate(df4.iterrows()):\n",
    "        # Check if there is a comment line for the current row\n",
    "        if i < len(c1):\n",
    "            # Write the row name, values, and comment on the same line\n",
    "            line = str(index) + '\\t' + '\\t'.join(str(val) for val in row.values) + '\\t' + c1[i] + '\\n'\n",
    "        else:\n",
    "            # Write the row name and values without comment on the same line\n",
    "            line = str(index) + '\\t' + '\\t'.join(str(val) for val in row.values) + '\\n'\n",
    "        \n",
    "        # Write the line to the file\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47386d0b-4919-4399-9a89-c2227d2fe500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s5\n",
    "s5= [\n",
    "\"\"\"!! -----------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Define model options (optional)\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!!snowfallmodel:\t\t\t\t\t\t\t\t\n",
    "!!                  0 threshold temperature model\t\t\t\t\t\t\t\n",
    "!!                  1 inputdata (SFobs.txt)\t\t\t\t\t\t\t\n",
    "!!snowmeltmodel:\t\t\t\t\t\t\t\n",
    "!!                  0,1 temperature index             (with/without snowcover scaling)\t\t\t\t\t\t\t\n",
    "!!                  2   temperature + radiation index (with/without snowcover scaling)\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!!  snowevapmodel   0 off\t\t\t\t\t\t\t\n",
    "!!                  1 on\t\t\t\t\t\t\t\n",
    "!!                   \t\t\t\t\t\t\t\n",
    "!!  petmodel:  (potential evapotranspiration) (is shown in geodata for WWH)\t\t\t\t\t\t\t\n",
    "!!                  0 original HYPE temperature model (with Xobs epot replacement)\t\t\t\t\t\t\t\n",
    "!!                  1 original HYPE temperature model (without Xobs epot replacement)\t\t\t\t\t\t\t\n",
    "!!                  2 Modified Jensen-Haise \t\t\t\t\t\t\t\n",
    "!!                  3 Modified Hargreaves-Samani\t\t\t\t\t\t\t\n",
    "!!                  4 Priestly-Taylor\t\t\t\t\t\t\t\n",
    "!!                  5 FAo Penman-Monteith\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! lakeriverice:\t\t\t\t\t\t\t\n",
    "!!                  0 off\t\t\t\t\t\t\t\n",
    "!!                  1 on, old (simple) air-water heat exchange              (requires T2 water temperature model)\t\t\t\t\t\t\t\n",
    "!!                  2 on, new heatbalance model for air-water heat exchange (requires T2 water temperature model)\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! substance T2     switching on the new water temperature trace model\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! deepground       0   off    Deep groundwater (Aquifer) model options\t\t\t\t\t\t\t\n",
    "!!                  1,2 on\n",
    "!! Glacierini\t0 off 1 on\t(1 used for statefile preparation)\t\n",
    "!! Floodplain\t\t0, 1, 2, 3 (3 used for WWH)\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c88f024-b468-43cf-8c6a-fe213db79409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s5 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s5:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9daac7dd-bb7d-41a1-a027-7c961d20b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df5\n",
    "df5_row=['modeloption snowfallmodel','modeloption snowdensity','modeloption snowfalldist','modeloption snowheat','modeloption snowmeltmodel','modeloption snowevaporation','modeloption lakeriverice','modeloption deepground','modeloption glacierini','modeloption floodmodel','modeloption frozensoil','modeloption infiltration','modeloption surfacerunoff','modeloption petmodel','modeloption wetlandmodel']\n",
    "df5_val=[0,0,2,0,2,1,0,0,1,0,2,3,0,3,2]\n",
    "df5=pd.DataFrame(df5_val, index=df5_row, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a03c40b8-ba13-4871-9b1f-35b64e3253c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df5\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df5.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20217760-e459-40a1-bf06-8c447f76038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s6\n",
    "s6= [\n",
    "\"\"\"!! ------------------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Define outputs\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! meanperiod 1=daymean, 2=weekmean, 3=monthmean, 4=yearmean, 5=total period mean\t\t\t\t\t\t\t\n",
    "!! output variables: see http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables \n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! BASIN outputs \n",
    "!! The present basins are some large rivers distributed over different continents\n",
    "!! -----------------\t\t\t\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dd363e1-65e8-4ef7-af75-402185642004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s6 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s6:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eab19d7e-1460-4732-8326-c618fa393760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df6 for basin outputs\n",
    "b1=['cout','rout']\n",
    "b2=[1]\n",
    "b3=[3]\n",
    "b4=[58183,58242]\n",
    "df6_row=['basinoutput variable','basinoutput meanperiod','basinoutput decimals','basinoutput subbasin']\n",
    "df6=pd.DataFrame([b1,b2,b3,b4], index=df6_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebd6d0ac-0161-4e9f-a901-7da01cbde49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>basinoutput variable</th>\n",
       "      <td>cout</td>\n",
       "      <td>rout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basinoutput meanperiod</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basinoutput decimals</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basinoutput subbasin</th>\n",
       "      <td>58183</td>\n",
       "      <td>58242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0      1\n",
       "basinoutput variable     cout   rout\n",
       "basinoutput meanperiod      1   None\n",
       "basinoutput decimals        3   None\n",
       "basinoutput subbasin    58183  58242"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c72afac9-afd8-43ce-bc6a-49951470009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df5\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df6.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87ccb9fe-d79a-435e-80d0-65bed6716160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s7\n",
    "s7= [\n",
    "\"\"\"!! -----------------\t\t\t\t\t\t\t\n",
    "!! TIME outputs \n",
    "!! -----------------\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1513cbf2-2ab7-404a-b4b5-47c98d6de188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s7 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s7:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f8d0782-14bb-4c95-994f-41a321c8b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df7 for basin outputs\n",
    "a1='cout'\n",
    "a2=[1]\n",
    "a3=[3]\n",
    "a4=[58183,58242]\n",
    "#df7_row=['timeoutput variable','timeoutput meanperiod','timeoutput decimals','timeoutput subbasin']\n",
    "#df7=pd.DataFrame([a1,a2,a3,a4], index=df7_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "087634de-3cea-4579-86f1-ea1d4f3cb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7={'timeoutput variable': a1, \n",
    "     'timeoutput meanperiod':1,\n",
    "     'timeoutput decimals':3,\n",
    "     'timeoutput subbasin':'58183\\t58242'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3342f00-3aa1-46aa-98b6-cec5d8770d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d509470b-10b5-47eb-a482-e01b3e916fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'a') as file:\n",
    "    for key,value in df7.items():\n",
    "        a=str(key)+'\\t'+str(value)+'\\n'\n",
    "        file.write(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffafd561-805d-43b6-bf7d-a0c619f01884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df7\n",
    "#with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "  #  df7.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0064daf-525d-4e09-8d6f-6768852500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s8\n",
    "s8= [\n",
    "\"\"\"!! -----------------\t\t\t\t\t\t\t\n",
    "!! MAP outputs\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! mapoutput variable\tcout cprc ctmp\n",
    "!! mapoutput decimals\t3\t\t\t\t\t\t\n",
    "!! mapoutput meanperiod\t5\t\t\t\t\t\t\n",
    "!! ------------------------------------------------------------------------------------\t\t\t\t\t\t\t\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! Select criteria for model evaluation and automatic calibration\n",
    "!!\t\t\t\t\t\t\t\n",
    "!! -----------------\t\t\t\t\t\t\t\n",
    "!! General settings\n",
    "!! -----------------\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a65b2fc7-e39f-41d5-9bf0-986076bae87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s8 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s8:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5e33fe5-a859-4b89-b01b-4cc66319afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df8 for basin outputs\n",
    "c2=[1]\n",
    "c3=[30]\n",
    "c4=[58183,58242]\n",
    "#df8_row=['crit meanperiod','crit datalimit','crit subbasin']\n",
    "#df8=pd.DataFrame([c2,c3,c4], index=df8_row, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3b4a9c9-9ef4-4bec-99a9-f8a65d5ecff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8={'crit meanperiod': 1, \n",
    "     'crit datalimit':30,\n",
    "     'crit subbasin':'58183\\t58242'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5e73804-eb76-44fe-9728-0fddfca0572d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crit meanperiod': 1, 'crit datalimit': 30, 'crit subbasin': '58183\\t58242'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5beecaa7-a027-4136-8624-c487903f81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'a') as file:\n",
    "    for key,value in df8.items():\n",
    "        a=str(key)+'\\t'+str(value)+'\\n'\n",
    "        file.write(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cad0638d-a508-4022-8b41-845380139997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out s9\n",
    "s9= [\n",
    "\"\"\"!! -----------------\t\t\t\n",
    "!! Criterion-specific settings\n",
    "!! -----------------\t\t\t\t\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39bdb8c8-0a82-4e97-b7bf-61e176411d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write s9 in output file\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the commented lines\n",
    "    for line in s9:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40b90d33-3a7e-4448-84b1-2b9c03df845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df9 for basin outputs\n",
    "d1=['MKG']\n",
    "d2=['cout']\n",
    "d3=['rout']\n",
    "d4=[1]\n",
    "df9_row=['crit 1 criterion','crit 1 cvariable','crit 1 rvariable','crit 1 weight']\n",
    "df9=pd.DataFrame([d1,d2,d3,d4], index=df9_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0da4554-74b6-4a04-8f91-65b908b35885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append df9\n",
    "with open(output_file, 'a') as file:\n",
    "    # Write the DataFrame to the file\n",
    "    df9.to_csv(file, sep='\\t', index=True, header=False, line_terminator='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easymore-env",
   "language": "python",
   "name": "easymore-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
